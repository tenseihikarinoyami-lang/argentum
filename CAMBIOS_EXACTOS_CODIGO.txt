â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                               â•‘
â•‘                      CAMBIOS EXACTOS DE CÃ“DIGO REALIZADOS                    â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


FILE 1: signal_async_processor.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[CAMBIO 1] - LÃ­nea 36: Actualizar docstring
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ANTES:
    - Performance tracking

DESPUÃ‰S:
    - Performance tracking
    - ğŸ¯ ANTI-DUPLICATE: Prevents duplicate signals for same asset


[CAMBIO 2] - LÃ­neas 59-60: NUEVAS variables de deduplicaciÃ³n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
AGREGADO:
    # ğŸ¯ ANTI-DUPLICATE: Track queued signals per asset
    self.queued_assets: Dict[str, Dict[str, Any]] = {}  # asset -> signal being processed
    self.processing_lock: threading.Lock = threading.Lock()


[CAMBIO 3] - LÃ­nea 79-80: DocumentaciÃ³n mejorada en queue_signal
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ANTES:
    """
    Queue a signal for processing.
    
    Args:
        signal_data: Signal data dictionary
        priority: Priority level
    
    Returns:
        True if queued successfully, False if queue full
    """

DESPUÃ‰S:
    """
    Queue a signal for processing.
    
    ğŸ¯ ANTI-DUPLICATE: Only queue if no signal for this asset is already queued.
    
    Args:
        signal_data: Signal data dictionary
        priority: Priority level
    
    Returns:
        True if queued successfully, False if queue full or duplicate
    """


[CAMBIO 4] - LÃ­neas 89-105: NUEVA LÃ“GICA anti-duplicados en queue_signal()
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
AGREGADO AL INICIO:
    asset = signal_data.get('asset')
    
    # ğŸ¯ ANTI-DUPLICATE: Check if signal already queued for this asset
    with self.processing_lock:
        if asset in self.queued_assets:
            logger.warning(f"[ASYNC] âš ï¸ DUPLICATE REJECTED: {asset} already has a queued signal. Ignoring this one.")
            self.failed_count += 1
            return False
        
        # Mark this asset as having a queued signal
        self.queued_assets[asset] = signal_data


[CAMBIO 5] - LÃ­neas 106-113: Manejar error de Queue Full
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
AGREGADO EN EXCEPCIÃ“N queue.Full:
    logger.warning(f"[ASYNC] Queue full, rejecting signal for {asset}")
    # Remove from queued_assets since we failed to queue
    with self.processing_lock:
        if asset in self.queued_assets:
            del self.queued_assets[asset]


[CAMBIO 6] - LÃ­neas 178-189: NUEVA LIMPIEZA en _process_batch
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
AGREGADO DESPUÃ‰S DE PROCESAR:
    # ğŸ¯ ANTI-DUPLICATE: Remove from queued_assets after processing
    with self.processing_lock:
        if asset in self.queued_assets:
            del self.queued_assets[asset]

AGREGADO EN EXCEPCIÃ“N:
    # ğŸ¯ ANTI-DUPLICATE: Clean up on error
    asset = signal_data.get('asset')
    with self.processing_lock:
        if asset in self.queued_assets:
            del self.queued_assets[asset]


[CAMBIO 7] - LÃ­nea 229: NUEVA MÃ‰TRICA en get_stats
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
AGREGADO:
    # ğŸ¯ ANTI-DUPLICATE: Include deduplication stats
    with self.processing_lock:
        queued_count = len(self.queued_assets)
    
    return {
        ...
        'queued_assets': queued_count,  # ğŸ¯ NEW: How many assets have signals being processed
        ...
    }


FILE 2: real_time_monitor.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[CAMBIO 1] - LÃ­nea 65: CAMBIO CRÃTICO - Tiempo por activo
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ANTES:
    self.time_per_asset = 8.0  # 8 seconds per asset

DESPUÃ‰S:
    self.time_per_asset = 60.0  # ğŸ¯ FIXED: 60 seconds per asset (was 8s, now focused monitoring)


[CAMBIO 2] - LÃ­nea 67: NUEVO intervalo de anÃ¡lisis
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
AGREGADO:
    self.analysis_interval = 3.0  # ğŸ¯ NEW: Analyze every 3 seconds during the 60s window


[CAMBIO 3] - LÃ­nea 214: NUEVO MÃ‰TODO - _focused_monitoring_phase()
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
AGREGADO COMPLETO NUEVO MÃ‰TODO (lÃ­neas 311-352):

def _focused_monitoring_phase(self, asset: str, cycle_count: int) -> None:
    """
    ğŸ¯ NEW: Focused 60-second monitoring of a single asset.
    
    This method ensures:
    1. Monitor stays on this asset for exactly 60 seconds
    2. Multiple analyses happen within those 60 seconds
    3. Other assets are IGNORED during this period
    4. Only signals for THIS asset are generated
    """
    logger.info(f"[FOCUS] ğŸ¯ Starting 60-second focused phase on {asset}")
    
    start_time = time.time()
    analysis_count = 0
    last_analysis_time = start_time
    
    while time.time() - start_time < self.time_per_asset and self.running:
        try:
            current_time = time.time()
            elapsed = current_time - start_time
            time_remaining = self.time_per_asset - elapsed
            
            # Perform analysis every 3 seconds during the 60-second window
            if current_time - last_analysis_time >= self.analysis_interval:
                analysis_count += 1
                logger.info(f"[FOCUS] [{analysis_count}] Analyzing {asset} - {elapsed:.1f}s elapsed (â±ï¸  {time_remaining:.1f}s remaining)")
                
                self._analyze_asset(asset)
                last_analysis_time = current_time
            
            # Small sleep to avoid CPU spinning
            time.sleep(0.5)
            
        except Exception as e:
            logger.error(f"[FOCUS] Error during focused monitoring of {asset}: {e}")
            time.sleep(1)
    
    logger.info(f"[FOCUS] âœ… 60-second focused phase complete on {asset} ({analysis_count} analyses performed)")


[CAMBIO 4] - LÃ­neas 215-231: ACTUALIZAR lÃ³gica de ciclo en _monitor_loop()
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ANTES (secciÃ³n "else"):
    # Modo de rotaciÃ³n normal
    logger.info(f"\n[CYCLE {cycle_count}] â¡ï¸ Rotando a: {current_asset}")
    logger.info(f"[CYCLE {cycle_count}] [1/4] Changing asset...")
    change_success = self._change_to_asset(current_asset)
    if not change_success:
        logger.warning(f"[CYCLE {cycle_count}] âš ï¸ Asset change failed, skipping")
        asset_index += 1
        continue
    
    logger.info(f"[CYCLE {cycle_count}] [2/4] Waiting for WebSocket data...")
    self._wait_for_websocket_data(current_asset)
    
    logger.info(f"[CYCLE {cycle_count}] [3/4] Analyzing asset...")
    self._analyze_asset(current_asset)
    
    logger.info(f"[CYCLE {cycle_count}] [4/4] âœ… Cycle complete")
    asset_index += 1

DESPUÃ‰S:
    # Modo de rotaciÃ³n normal - ğŸ¯ FIXED: 60 second focused monitoring
    logger.info(f"\n[CYCLE {cycle_count}] â¡ï¸ Rotando a: {current_asset}")
    logger.info(f"[CYCLE {cycle_count}] [1/3] Changing asset...")
    change_success = self._change_to_asset(current_asset)
    if not change_success:
        logger.warning(f"[CYCLE {cycle_count}] âš ï¸ Asset change failed, skipping")
        asset_index += 1
        continue
    
    logger.info(f"[CYCLE {cycle_count}] [2/3] Waiting for WebSocket data...")
    self._wait_for_websocket_data(current_asset)
    
    logger.info(f"[CYCLE {cycle_count}] [3/3] â±ï¸  Focused analysis phase (60 seconds)...")
    # ğŸ¯ FIXED: Focus on this asset for 60 seconds with periodic analysis
    self._focused_monitoring_phase(current_asset, cycle_count)
    
    logger.info(f"[CYCLE {cycle_count}] âœ… Cycle complete - Moving to next asset in {self.time_per_asset}s")
    asset_index += 1


FILE 3: main.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[CAMBIO 1] - LÃ­nea 467: MEJORAR log de estadÃ­sticas ASYNC
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ANTES:
    logger.info(f"[ASYNC] Queue: {async_stats['queue_size']} | Processed: {async_stats['processed_signals']} | Avg Time: {async_stats['avg_processing_time']}")

DESPUÃ‰S:
    logger.info(f"[ASYNC] Queue: {async_stats['queue_size']} | Queued Assets: {async_stats.get('queued_assets', 0)} | Processed: {async_stats['processed_signals']} | Avg Time: {async_stats['avg_processing_time']}")
                                                                       â†‘
                                                    Nuevo contador de deduplicaciÃ³n


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

RESUMEN DE CAMBIOS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… CORRECCIÃ“N 1: Anti-duplicados
   - Archivos modificados: 1 (signal_async_processor.py)
   - LÃ­neas agregadas: ~40
   - MÃ©todos modificados: 2 (queue_signal, _process_batch, get_stats)
   - Nuevo diccionario: queued_assets

âœ… CORRECCIÃ“N 2: RotaciÃ³n 60 segundos  
   - Archivos modificados: 2 (real_time_monitor.py, main.py)
   - LÃ­neas agregadas: ~60
   - MÃ©todos nuevos: 1 (_focused_monitoring_phase)
   - MÃ©todos modificados: 1 (_monitor_loop)
   - Variable clave: time_per_asset (8.0 â†’ 60.0)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Status: âœ… CAMBIOS COMPLETADOS
Total de archivos: 3
Total de lÃ­neas modificadas/agregadas: ~100
Complejidad: BAJA (cambios localizados y seguros)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
